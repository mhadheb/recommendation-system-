{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_RecommendationSystem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oSFhx5QEGw-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "330bf518-6df1-4453-f5ca-9fff079b4927"
      },
      "source": [
        "from keras import models\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "model = load_model('regression_model_test.h5')\n",
        "dataset = pd.read_csv('movie500k.csv')\n",
        "movies = pd.read_csv('movie.csv')\n",
        "import numpy as np\n",
        "uID = int(input(\"Enter the user id to whom you want to recommend : \"))\n",
        "movie_data = np.array(list(set(dataset.movieId)))\n",
        "user = np.array([uID for i in range(len(movie_data))])\n",
        "predictions = model.predict([user, movie_data])\n",
        "predictions = np.array([a[0] for a in predictions])\n",
        "recommended_movie_ids = (-predictions).argsort()[:10]\n",
        "liste_UserBasedApp=[]\n",
        "for i in recommended_movie_ids:\n",
        "  liste_UserBasedApp.append(movies.iloc[i]['title'])\n",
        "print(movies[movies['movieId'].isin(recommended_movie_ids)].title)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the user id to whom you want to recommend : 450\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8c56265840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['City of Lost Children, The (CitÃ© des enfants perdus, La) (1995)',\n",
              " 'Persuasion (1995)',\n",
              " 'Sense and Sensibility (1995)',\n",
              " 'Toy Story (1995)',\n",
              " 'Dead Man Walking (1995)',\n",
              " 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)',\n",
              " 'Richard III (1995)',\n",
              " 'Heat (1995)',\n",
              " 'Casino (1995)',\n",
              " 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tj9cQvBjHSVy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "53567b3d-1f33-4b51-d43e-5e432884e812"
      },
      "source": [
        "!pip3 install rake-nltk\n",
        "from rake_nltk import Rake\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "df = pd.read_csv('https://query.data.world/s/uikepcpffyo2nhig52xxeevdialfl7')\n",
        "df = df[['Title','Genre','Director','Actors','Plot']]\n",
        "\n",
        "# discarding the commas between the actors' full names and getting only the first three names\n",
        "df['Actors'] = df['Actors'].map(lambda x: x.split(',')[:3])\n",
        "\n",
        "# putting the genres in a list of words\n",
        "df['Genre'] = df['Genre'].map(lambda x: x.lower().split(','))\n",
        "\n",
        "df['Director'] = df['Director'].map(lambda x: x.split(' '))\n",
        "\n",
        "# merging together first and last name for each actor and director, so it's considered as one word \n",
        "# and there is no mix up between people sharing a first name\n",
        "for index, row in df.iterrows():\n",
        "    row['Actors'] = [x.lower().replace(' ','') for x in row['Actors']]\n",
        "    row['Director'] = ''.join(row['Director']).lower()\n",
        "\n",
        "# initializing the new column\n",
        "df['Key_words'] = \"\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    plot = row['Plot']\n",
        "    \n",
        "    # instantiating Rake, by default is uses english stopwords from NLTK\n",
        "    # and discard all puntuation characters\n",
        "    r = Rake()\n",
        "\n",
        "    # extracting the words by passing the text\n",
        "    r.extract_keywords_from_text(plot)\n",
        "\n",
        "    # getting the dictionary whith key words and their scores\n",
        "    key_words_dict_scores = r.get_word_degrees()\n",
        "    \n",
        "    # assigning the key words to the new column\n",
        "    row['Key_words'] = list(key_words_dict_scores.keys())\n",
        "\n",
        "# dropping the Plot column\n",
        "df.drop(columns = ['Plot'], inplace = True)\n",
        "\n",
        "df.set_index('Title', inplace = True)\n",
        "\n",
        "df['bag_of_words'] = ''\n",
        "columns = df.columns\n",
        "for index, row in df.iterrows():\n",
        "    words = ''\n",
        "    for col in columns:\n",
        "        if col != 'Director':\n",
        "            words = words + ' '.join(row[col])+ ' '\n",
        "        else:\n",
        "            words = words + row[col]+ ' '\n",
        "    row['bag_of_words'] = words\n",
        "    \n",
        "df.drop(columns = [col for col in df.columns if col!= 'bag_of_words'], inplace = True)\n",
        "\n",
        "# instantiating and generating the count matrix\n",
        "count = CountVectorizer()\n",
        "count_matrix = count.fit_transform(df['bag_of_words'])\n",
        "\n",
        "# creating a Series for the movie titles so they are associated to an ordered numerical\n",
        "# list I will use later to match the indexes\n",
        "indices = pd.Series(df.index)\n",
        "\n",
        "# generating the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "# function that takes in movie title as input and returns the top 10 recommended movies\n",
        "def recommendations(title, cosine_sim = cosine_sim):\n",
        "    \n",
        "    recommended_movies = []\n",
        "    \n",
        "    # gettin the index of the movie that matches the title\n",
        "    idx = indices[indices == title].index[0]\n",
        "\n",
        "    # creating a Series with the similarity scores in descending order\n",
        "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "\n",
        "    # getting the indexes of the 10 most similar movies\n",
        "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
        "    \n",
        "    # populating the list with the titles of the best 10 matching movies\n",
        "    for i in top_10_indexes:\n",
        "        recommended_movies.append(list(df.index)[i])\n",
        "        \n",
        "    return recommended_movies\n",
        "\n",
        "MovieName = str(input(\"Enter the name of the movie : \"))\n",
        "liste_ContentBasedApp=recommendations(MovieName)\n",
        "liste_ContentBasedApp"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rake-nltk) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->rake-nltk) (1.15.0)\n",
            "Enter the name of the movie : Fargo\n",
            "['No Country for Old Men', 'The Departed', 'Rope', 'The Godfather', 'Reservoir Dogs', 'The Godfather: Part II', 'On the Waterfront', 'Goodfellas', 'Arsenic and Old Lace', 'The Big Lebowski']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_YeVdIDzB0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lg9YGG9zB0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#User Based Approach\n",
        "from keras import models\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "!pip3 install rake-nltk\n",
        "model = load_model('regression_model_test.h5')\n",
        "dataset = pd.read_csv('movie500k.csv')\n",
        "movies = pd.read_csv('movie.csv')\n",
        "import numpy as np\n",
        "\n",
        "# Input UserId and Name of the movie\n",
        "uID = int(input(\"Enter the user id to whom you want to recommend : \"))\n",
        "MovieName = str(input(\"Enter the name of the movie : \"))\n",
        "\n",
        "\n",
        "movie_data = np.array(list(set(dataset.movieId)))\n",
        "user = np.array([uID for i in range(len(movie_data))])\n",
        "predictions = model.predict([user, movie_data])\n",
        "predictions = np.array([a[0] for a in predictions])\n",
        "recommended_movie_ids = (-predictions).argsort()[:10]\n",
        "liste_UserBasedApp=[]\n",
        "for i in recommended_movie_ids:\n",
        "  liste_UserBasedApp.append(movies.iloc[i]['title'])\n",
        "\n",
        "\n",
        "# Content Based Approach\n",
        "\n",
        "from rake_nltk import Rake\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "df = pd.read_csv('https://query.data.world/s/uikepcpffyo2nhig52xxeevdialfl7')\n",
        "df = df[['Title','Genre','Director','Actors','Plot']]\n",
        "\n",
        "# discarding the commas between the actors' full names and getting only the first three names\n",
        "df['Actors'] = df['Actors'].map(lambda x: x.split(',')[:3])\n",
        "\n",
        "# putting the genres in a list of words\n",
        "df['Genre'] = df['Genre'].map(lambda x: x.lower().split(','))\n",
        "\n",
        "df['Director'] = df['Director'].map(lambda x: x.split(' '))\n",
        "\n",
        "# merging together first and last name for each actor and director, so it's considered as one word \n",
        "# and there is no mix up between people sharing a first name\n",
        "for index, row in df.iterrows():\n",
        "    row['Actors'] = [x.lower().replace(' ','') for x in row['Actors']]\n",
        "    row['Director'] = ''.join(row['Director']).lower()\n",
        "\n",
        "# initializing the new column\n",
        "df['Key_words'] = \"\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    plot = row['Plot']\n",
        "    \n",
        "    # instantiating Rake, by default is uses english stopwords from NLTK\n",
        "    # and discard all puntuation characters\n",
        "    r = Rake()\n",
        "\n",
        "    # extracting the words by passing the text\n",
        "    r.extract_keywords_from_text(plot)\n",
        "\n",
        "    # getting the dictionary whith key words and their scores\n",
        "    key_words_dict_scores = r.get_word_degrees()\n",
        "    \n",
        "    # assigning the key words to the new column\n",
        "    row['Key_words'] = list(key_words_dict_scores.keys())\n",
        "\n",
        "# dropping the Plot column\n",
        "df.drop(columns = ['Plot'], inplace = True)\n",
        "\n",
        "df.set_index('Title', inplace = True)\n",
        "\n",
        "df['bag_of_words'] = ''\n",
        "columns = df.columns\n",
        "for index, row in df.iterrows():\n",
        "    words = ''\n",
        "    for col in columns:\n",
        "        if col != 'Director':\n",
        "            words = words + ' '.join(row[col])+ ' '\n",
        "        else:\n",
        "            words = words + row[col]+ ' '\n",
        "    row['bag_of_words'] = words\n",
        "    \n",
        "df.drop(columns = [col for col in df.columns if col!= 'bag_of_words'], inplace = True)\n",
        "\n",
        "# instantiating and generating the count matrix\n",
        "count = CountVectorizer()\n",
        "count_matrix = count.fit_transform(df['bag_of_words'])\n",
        "\n",
        "# creating a Series for the movie titles so they are associated to an ordered numerical\n",
        "# list I will use later to match the indexes\n",
        "indices = pd.Series(df.index)\n",
        "\n",
        "# generating the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
        "\n",
        "# function that takes in movie title as input and returns the top 10 recommended movies\n",
        "def recommendations(title, cosine_sim = cosine_sim):\n",
        "    \n",
        "    recommended_movies = []\n",
        "    \n",
        "    # gettin the index of the movie that matches the title\n",
        "    idx = indices[indices == title].index[0]\n",
        "\n",
        "    # creating a Series with the similarity scores in descending order\n",
        "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "\n",
        "    # getting the indexes of the 10 most similar movies\n",
        "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
        "    \n",
        "    # populating the list with the titles of the best 10 matching movies\n",
        "    for i in top_10_indexes:\n",
        "        recommended_movies.append(list(df.index)[i])\n",
        "        \n",
        "    return recommended_movies\n",
        "\n",
        "\n",
        "liste_ContentBasedApp=recommendations(MovieName)\n",
        "\n",
        "# Affichage\n",
        "print('User Based Approach Recommendation :')\n",
        "liste_UserBasedApp\n",
        "print('Content Based Approach Recommendation :')\n",
        "liste_ContentBasedApp"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}